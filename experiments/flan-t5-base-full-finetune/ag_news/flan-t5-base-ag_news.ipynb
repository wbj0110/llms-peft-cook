{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Finetuning the model on financial_phrasebank dataset, that consists of pairs of text-labels to classify financial-related sentences, if they are either <span style=\"color: red;\">positive</span>, <span style=\"color: purple;\">neutral</span> or <span style=\"color: green;\">negative</span>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.Experimental Setup1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1 Run code on CPU version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\r\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\r\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\r\n",
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\r\n",
      "  warnings.warn(\r\n",
      "use AutoModelForSeq2SeqLM load  model.\r\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\r\n",
      "trainable params: 247577856 || all params: 247577856 || trainable%: 100.0\r\n",
      "tokenizer padding setting: </s>\r\n",
      "Sentence: 5 EU ministers back digital passports FLORENCE Interior ministers from the five largest West European countries have agreed to adopt digital fingerprinting on passports, officials here said, but a second day of talks on Monday found them still deadlocked on a plan to create migrant holding \r\n",
      "number of labels:4\r\n",
      "Running tokenizer on dataset: 100%|█| 12160/12160 [00:00<00:00, 21227.72 example\r\n",
      "Running tokenizer on dataset: 100%|█| 3040/3040 [00:00<00:00, 14899.12 examples/\r\n",
      "  0%|                                                   | 0/115 [00:00<?, ?it/s]/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 1.3363, 'learning_rate': 0.0009130434782608695, 'epoch': 0.42}         \r\n",
      "{'loss': 0.2039, 'learning_rate': 0.0008260869565217392, 'epoch': 0.84}         \r\n",
      " 20%|████████                                | 23/115 [32:49<2:10:02, 84.81s/it]\r\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001B[A\r\n",
      "  4%|█▊                                          | 2/48 [00:01<00:42,  1.09it/s]\u001B[A\r\n",
      "  6%|██▊                                         | 3/48 [00:03<00:58,  1.31s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 4/48 [00:05<01:06,  1.51s/it]\u001B[A\r\n",
      " 10%|████▌                                       | 5/48 [00:07<01:10,  1.63s/it]\u001B[A\r\n",
      " 12%|█████▌                                      | 6/48 [00:09<01:11,  1.70s/it]\u001B[A\r\n",
      " 15%|██████▍                                     | 7/48 [00:11<01:11,  1.75s/it]\u001B[A\r\n",
      " 17%|███████▎                                    | 8/48 [00:12<01:11,  1.78s/it]\u001B[A\r\n",
      " 19%|████████▎                                   | 9/48 [00:14<01:10,  1.80s/it]\u001B[A\r\n",
      " 21%|████████▉                                  | 10/48 [00:16<01:09,  1.82s/it]\u001B[A\r\n",
      " 23%|█████████▊                                 | 11/48 [00:18<01:08,  1.85s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 12/48 [00:20<01:06,  1.86s/it]\u001B[A\r\n",
      " 27%|███████████▋                               | 13/48 [00:22<01:05,  1.86s/it]\u001B[A\r\n",
      " 29%|████████████▌                              | 14/48 [00:24<01:03,  1.87s/it]\u001B[A\r\n",
      " 31%|█████████████▍                             | 15/48 [00:26<01:01,  1.87s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 16/48 [00:27<01:00,  1.88s/it]\u001B[A\r\n",
      " 35%|███████████████▏                           | 17/48 [00:29<00:58,  1.89s/it]\u001B[A\r\n",
      " 38%|████████████████▏                          | 18/48 [00:31<00:56,  1.88s/it]\u001B[A\r\n",
      " 40%|█████████████████                          | 19/48 [00:33<00:54,  1.89s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 20/48 [00:35<00:52,  1.89s/it]\u001B[A\r\n",
      " 44%|██████████████████▊                        | 21/48 [00:37<00:51,  1.90s/it]\u001B[A\r\n",
      " 46%|███████████████████▋                       | 22/48 [00:39<00:49,  1.90s/it]\u001B[A\r\n",
      " 48%|████████████████████▌                      | 23/48 [00:41<00:47,  1.91s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 24/48 [00:43<00:45,  1.91s/it]\u001B[A\r\n",
      " 52%|██████████████████████▍                    | 25/48 [00:45<00:44,  1.91s/it]\u001B[A\r\n",
      " 54%|███████████████████████▎                   | 26/48 [00:47<00:42,  1.91s/it]\u001B[A\r\n",
      " 56%|████████████████████████▏                  | 27/48 [00:48<00:40,  1.91s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 28/48 [00:50<00:38,  1.92s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▉                 | 29/48 [00:52<00:36,  1.92s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▉                | 30/48 [00:54<00:34,  1.92s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▊               | 31/48 [00:56<00:32,  1.92s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 32/48 [00:58<00:30,  1.93s/it]\u001B[A\r\n",
      " 69%|█████████████████████████████▌             | 33/48 [01:00<00:28,  1.93s/it]\u001B[A\r\n",
      " 71%|██████████████████████████████▍            | 34/48 [01:02<00:27,  1.94s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▎           | 35/48 [01:04<00:25,  1.94s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 36/48 [01:06<00:23,  1.94s/it]\u001B[A\r\n",
      " 77%|█████████████████████████████████▏         | 37/48 [01:08<00:21,  1.95s/it]\u001B[A\r\n",
      " 79%|██████████████████████████████████         | 38/48 [01:10<00:19,  1.94s/it]\u001B[A\r\n",
      " 81%|██████████████████████████████████▉        | 39/48 [01:12<00:17,  1.94s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 40/48 [01:14<00:15,  1.95s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▋      | 41/48 [01:16<00:13,  1.96s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▋     | 42/48 [01:18<00:11,  1.96s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▌    | 43/48 [01:20<00:09,  1.97s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 44/48 [01:22<00:07,  1.98s/it]\u001B[A\r\n",
      " 94%|████████████████████████████████████████▎  | 45/48 [01:24<00:05,  1.98s/it]\u001B[A\r\n",
      " 96%|█████████████████████████████████████████▏ | 46/48 [01:26<00:03,  1.98s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████ | 47/48 [01:28<00:01,  1.98s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.14713455736637115, 'eval_accuracy': 0.9517543859649122, 'eval_precision': 0.9517858417151384, 'eval_recall': 0.9517543859649122, 'eval_f1': 0.9515836261886427, 'eval_runtime': 91.1308, 'eval_samples_per_second': 33.359, 'eval_steps_per_second': 0.527, 'epoch': 0.97}\r\n",
      " 20%|████████                                | 23/115 [35:23<2:10:02, 84.81s/it]\r\n",
      "100%|███████████████████████████████████████████| 48/48 [01:29<00:00,  1.74s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.1339, 'learning_rate': 0.0007391304347826086, 'epoch': 1.26}         \r\n",
      "{'loss': 0.0915, 'learning_rate': 0.0006521739130434783, 'epoch': 1.68}         \r\n",
      " 41%|███████████████▌                      | 47/115 [1:08:37<1:39:11, 87.52s/it]\r\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001B[A\r\n",
      "  4%|█▊                                          | 2/48 [00:02<01:00,  1.31s/it]\u001B[A\r\n",
      "  6%|██▊                                         | 3/48 [00:05<01:22,  1.84s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 4/48 [00:07<01:34,  2.14s/it]\u001B[A\r\n",
      " 10%|████▌                                       | 5/48 [00:10<01:38,  2.30s/it]\u001B[A\r\n",
      " 12%|█████▌                                      | 6/48 [00:13<01:49,  2.61s/it]\u001B[A\r\n",
      " 15%|██████▍                                     | 7/48 [00:16<01:45,  2.58s/it]\u001B[A\r\n",
      " 17%|███████▎                                    | 8/48 [00:18<01:45,  2.64s/it]\u001B[A\r\n",
      " 19%|████████▎                                   | 9/48 [00:21<01:45,  2.69s/it]\u001B[A\r\n",
      " 21%|████████▉                                  | 10/48 [00:24<01:43,  2.71s/it]\u001B[A\r\n",
      " 23%|█████████▊                                 | 11/48 [00:27<01:42,  2.76s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 12/48 [00:30<01:39,  2.77s/it]\u001B[A\r\n",
      " 27%|███████████▋                               | 13/48 [00:33<01:37,  2.78s/it]\u001B[A\r\n",
      " 29%|████████████▌                              | 14/48 [00:36<01:37,  2.85s/it]\u001B[A\r\n",
      " 31%|█████████████▍                             | 15/48 [00:38<01:34,  2.86s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 16/48 [00:41<01:31,  2.87s/it]\u001B[A\r\n",
      " 35%|███████████████▏                           | 17/48 [00:44<01:30,  2.93s/it]\u001B[A\r\n",
      " 38%|████████████████▏                          | 18/48 [00:47<01:28,  2.95s/it]\u001B[A\r\n",
      " 40%|█████████████████                          | 19/48 [00:50<01:26,  2.97s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 20/48 [00:53<01:22,  2.96s/it]\u001B[A\r\n",
      " 44%|██████████████████▊                        | 21/48 [00:56<01:20,  2.97s/it]\u001B[A\r\n",
      " 46%|███████████████████▋                       | 22/48 [00:59<01:17,  2.99s/it]\u001B[A\r\n",
      " 48%|████████████████████▌                      | 23/48 [01:02<01:15,  3.02s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 24/48 [01:06<01:15,  3.13s/it]\u001B[A\r\n",
      " 52%|██████████████████████▍                    | 25/48 [01:08<01:04,  2.79s/it]\u001B[A\r\n",
      " 54%|███████████████████████▎                   | 26/48 [01:10<00:58,  2.66s/it]\u001B[A\r\n",
      " 56%|████████████████████████▏                  | 27/48 [01:12<00:52,  2.49s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 28/48 [01:14<00:47,  2.40s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▉                 | 29/48 [01:17<00:43,  2.29s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▉                | 30/48 [01:19<00:39,  2.22s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▊               | 31/48 [01:21<00:37,  2.21s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 32/48 [01:23<00:35,  2.23s/it]\u001B[A\r\n",
      " 69%|█████████████████████████████▌             | 33/48 [01:26<00:34,  2.33s/it]\u001B[A\r\n",
      " 71%|██████████████████████████████▍            | 34/48 [01:28<00:32,  2.35s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▎           | 35/48 [01:31<00:31,  2.40s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 36/48 [01:33<00:29,  2.43s/it]\u001B[A\r\n",
      " 77%|█████████████████████████████████▏         | 37/48 [01:35<00:26,  2.40s/it]\u001B[A\r\n",
      " 79%|██████████████████████████████████         | 38/48 [01:37<00:22,  2.29s/it]\u001B[A\r\n",
      " 81%|██████████████████████████████████▉        | 39/48 [01:39<00:20,  2.22s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 40/48 [01:42<00:18,  2.37s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▋      | 41/48 [01:44<00:16,  2.29s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▋     | 42/48 [01:46<00:13,  2.28s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▌    | 43/48 [01:49<00:11,  2.39s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 44/48 [01:52<00:10,  2.55s/it]\u001B[A\r\n",
      " 94%|████████████████████████████████████████▎  | 45/48 [01:54<00:07,  2.41s/it]\u001B[A\r\n",
      " 96%|█████████████████████████████████████████▏ | 46/48 [01:56<00:04,  2.32s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████ | 47/48 [01:59<00:02,  2.49s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.0973375216126442, 'eval_accuracy': 0.968421052631579, 'eval_precision': 0.9684685519341523, 'eval_recall': 0.968421052631579, 'eval_f1': 0.9683868969379985, 'eval_runtime': 123.6386, 'eval_samples_per_second': 24.588, 'eval_steps_per_second': 0.388, 'epoch': 1.98}\r\n",
      " 41%|███████████████▌                      | 47/115 [1:11:35<1:39:11, 87.52s/it]\r\n",
      "100%|███████████████████████████████████████████| 48/48 [02:01<00:00,  2.12s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0751, 'learning_rate': 0.0005652173913043478, 'epoch': 2.11}         \r\n",
      "{'loss': 0.046, 'learning_rate': 0.0004782608695652174, 'epoch': 2.53}          \r\n",
      "{'loss': 0.0388, 'learning_rate': 0.000391304347826087, 'epoch': 2.95}          \r\n",
      " 62%|██████████████████████▊              | 71/115 [1:54:50<1:23:04, 113.29s/it]\r\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001B[A\r\n",
      "  4%|█▊                                          | 2/48 [00:03<01:21,  1.78s/it]\u001B[A\r\n",
      "  6%|██▊                                         | 3/48 [00:07<01:54,  2.54s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 4/48 [00:10<02:12,  3.02s/it]\u001B[A\r\n",
      " 10%|████▌                                       | 5/48 [00:14<02:22,  3.31s/it]\u001B[A\r\n",
      " 12%|█████▌                                      | 6/48 [00:18<02:25,  3.46s/it]\u001B[A\r\n",
      " 15%|██████▍                                     | 7/48 [00:22<02:25,  3.54s/it]\u001B[A\r\n",
      " 17%|███████▎                                    | 8/48 [00:26<02:25,  3.65s/it]\u001B[A\r\n",
      " 19%|████████▎                                   | 9/48 [00:30<02:25,  3.72s/it]\u001B[A\r\n",
      " 21%|████████▉                                  | 10/48 [00:33<02:23,  3.76s/it]\u001B[A\r\n",
      " 23%|█████████▊                                 | 11/48 [00:38<02:23,  3.87s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 12/48 [00:42<02:21,  3.93s/it]\u001B[A\r\n",
      " 27%|███████████▋                               | 13/48 [00:46<02:18,  3.96s/it]\u001B[A\r\n",
      " 29%|████████████▌                              | 14/48 [00:50<02:15,  3.98s/it]\u001B[A\r\n",
      " 31%|█████████████▍                             | 15/48 [00:54<02:10,  3.97s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 16/48 [00:58<02:07,  3.97s/it]\u001B[A\r\n",
      " 35%|███████████████▏                           | 17/48 [01:02<02:08,  4.13s/it]\u001B[A\r\n",
      " 38%|████████████████▏                          | 18/48 [01:06<02:04,  4.15s/it]\u001B[A\r\n",
      " 40%|█████████████████                          | 19/48 [01:11<02:01,  4.18s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 20/48 [01:15<01:55,  4.13s/it]\u001B[A\r\n",
      " 44%|██████████████████▊                        | 21/48 [01:19<01:54,  4.24s/it]\u001B[A\r\n",
      " 46%|███████████████████▋                       | 22/48 [01:24<01:52,  4.34s/it]\u001B[A\r\n",
      " 48%|████████████████████▌                      | 23/48 [01:28<01:49,  4.39s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 24/48 [01:33<01:47,  4.47s/it]\u001B[A\r\n",
      " 52%|██████████████████████▍                    | 25/48 [01:37<01:40,  4.37s/it]\u001B[A\r\n",
      " 54%|███████████████████████▎                   | 26/48 [01:42<01:38,  4.49s/it]\u001B[A\r\n",
      " 56%|████████████████████████▏                  | 27/48 [01:46<01:34,  4.48s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 28/48 [01:50<01:28,  4.41s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▉                 | 29/48 [01:55<01:23,  4.37s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▉                | 30/48 [01:59<01:18,  4.38s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▊               | 31/48 [02:03<01:13,  4.31s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 32/48 [02:08<01:08,  4.31s/it]\u001B[A\r\n",
      " 69%|█████████████████████████████▌             | 33/48 [02:12<01:03,  4.26s/it]\u001B[A\r\n",
      " 71%|██████████████████████████████▍            | 34/48 [02:16<01:01,  4.36s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▎           | 35/48 [02:21<00:57,  4.40s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 36/48 [02:25<00:52,  4.39s/it]\u001B[A\r\n",
      " 77%|█████████████████████████████████▏         | 37/48 [02:29<00:47,  4.33s/it]\u001B[A\r\n",
      " 79%|██████████████████████████████████         | 38/48 [02:33<00:42,  4.25s/it]\u001B[A\r\n",
      " 81%|██████████████████████████████████▉        | 39/48 [02:37<00:37,  4.19s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 40/48 [02:41<00:33,  4.13s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▋      | 41/48 [02:47<00:31,  4.56s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▋     | 42/48 [02:53<00:29,  4.94s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▌    | 43/48 [02:58<00:24,  4.95s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 44/48 [03:02<00:19,  4.77s/it]\u001B[A\r\n",
      " 94%|████████████████████████████████████████▎  | 45/48 [03:06<00:13,  4.63s/it]\u001B[A\r\n",
      " 96%|█████████████████████████████████████████▏ | 46/48 [03:11<00:09,  4.59s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████ | 47/48 [03:16<00:04,  4.60s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.06731532514095306, 'eval_accuracy': 0.9822368421052632, 'eval_precision': 0.9822230567997747, 'eval_recall': 0.9822368421052632, 'eval_f1': 0.9822155855701226, 'eval_runtime': 203.0656, 'eval_samples_per_second': 14.971, 'eval_steps_per_second': 0.236, 'epoch': 2.99}\r\n",
      " 62%|██████████████████████▊              | 71/115 [1:58:51<1:23:04, 113.29s/it]\r\n",
      "100%|███████████████████████████████████████████| 48/48 [03:19<00:00,  4.20s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0223, 'learning_rate': 0.00030434782608695655, 'epoch': 3.37}        \r\n",
      "{'loss': 0.0155, 'learning_rate': 0.0002173913043478261, 'epoch': 3.79}         \r\n",
      " 83%|████████████████████████████████▏      | 95/115 [2:42:57<35:16, 105.84s/it]\r\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001B[A\r\n",
      "  4%|█▊                                          | 2/48 [00:01<00:43,  1.06it/s]\u001B[A\r\n",
      "  6%|██▊                                         | 3/48 [00:03<00:59,  1.33s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 4/48 [00:05<01:07,  1.54s/it]\u001B[A\r\n",
      " 10%|████▌                                       | 5/48 [00:07<01:12,  1.69s/it]\u001B[A\r\n",
      " 12%|█████▌                                      | 6/48 [00:09<01:13,  1.75s/it]\u001B[A\r\n",
      " 15%|██████▍                                     | 7/48 [00:11<01:13,  1.80s/it]\u001B[A\r\n",
      " 17%|███████▎                                    | 8/48 [00:13<01:13,  1.83s/it]\u001B[A\r\n",
      " 19%|████████▎                                   | 9/48 [00:15<01:12,  1.85s/it]\u001B[A\r\n",
      " 21%|████████▉                                  | 10/48 [00:17<01:10,  1.86s/it]\u001B[A\r\n",
      " 23%|█████████▊                                 | 11/48 [00:19<01:09,  1.88s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 12/48 [00:20<01:07,  1.89s/it]\u001B[A\r\n",
      " 27%|███████████▋                               | 13/48 [00:22<01:06,  1.89s/it]\u001B[A\r\n",
      " 29%|████████████▌                              | 14/48 [00:24<01:04,  1.90s/it]\u001B[A\r\n",
      " 31%|█████████████▍                             | 15/48 [00:26<01:02,  1.91s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 16/48 [00:28<01:01,  1.91s/it]\u001B[A\r\n",
      " 35%|███████████████▏                           | 17/48 [00:30<00:59,  1.91s/it]\u001B[A\r\n",
      " 38%|████████████████▏                          | 18/48 [00:32<00:57,  1.92s/it]\u001B[A\r\n",
      " 40%|█████████████████                          | 19/48 [00:34<00:55,  1.93s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 20/48 [00:36<00:54,  1.93s/it]\u001B[A\r\n",
      " 44%|██████████████████▊                        | 21/48 [00:38<00:52,  1.95s/it]\u001B[A\r\n",
      " 46%|███████████████████▋                       | 22/48 [00:40<00:50,  1.95s/it]\u001B[A\r\n",
      " 48%|████████████████████▌                      | 23/48 [00:42<00:48,  1.96s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 24/48 [00:44<00:47,  1.96s/it]\u001B[A\r\n",
      " 52%|██████████████████████▍                    | 25/48 [00:46<00:45,  1.96s/it]\u001B[A\r\n",
      " 54%|███████████████████████▎                   | 26/48 [00:48<00:43,  1.96s/it]\u001B[A\r\n",
      " 56%|████████████████████████▏                  | 27/48 [00:50<00:41,  1.96s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 28/48 [00:52<00:39,  1.97s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▉                 | 29/48 [00:54<00:37,  1.97s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▉                | 30/48 [00:56<00:35,  1.97s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▊               | 31/48 [00:57<00:33,  1.97s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 32/48 [00:59<00:31,  1.97s/it]\u001B[A\r\n",
      " 69%|█████████████████████████████▌             | 33/48 [01:01<00:29,  1.98s/it]\u001B[A\r\n",
      " 71%|██████████████████████████████▍            | 34/48 [01:03<00:27,  1.98s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▎           | 35/48 [01:05<00:25,  1.99s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 36/48 [01:07<00:23,  1.99s/it]\u001B[A\r\n",
      " 77%|█████████████████████████████████▏         | 37/48 [01:09<00:22,  2.01s/it]\u001B[A\r\n",
      " 79%|██████████████████████████████████         | 38/48 [01:12<00:20,  2.01s/it]\u001B[A\r\n",
      " 81%|██████████████████████████████████▉        | 39/48 [01:14<00:18,  2.01s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 40/48 [01:16<00:16,  2.01s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▋      | 41/48 [01:18<00:14,  2.01s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▋     | 42/48 [01:20<00:12,  2.01s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▌    | 43/48 [01:22<00:10,  2.02s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 44/48 [01:24<00:08,  2.02s/it]\u001B[A\r\n",
      " 94%|████████████████████████████████████████▎  | 45/48 [01:26<00:06,  2.02s/it]\u001B[A\r\n",
      " 96%|█████████████████████████████████████████▏ | 46/48 [01:28<00:04,  2.02s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████ | 47/48 [01:30<00:02,  2.03s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.06979439407587051, 'eval_accuracy': 0.9853070175438596, 'eval_precision': 0.9853092138814298, 'eval_recall': 0.9853070175438596, 'eval_f1': 0.9852958116540997, 'eval_runtime': 93.2589, 'eval_samples_per_second': 32.597, 'eval_steps_per_second': 0.515, 'epoch': 4.0}\r\n",
      " 83%|████████████████████████████████▏      | 95/115 [2:44:31<35:16, 105.84s/it]\r\n",
      "100%|███████████████████████████████████████████| 48/48 [01:31<00:00,  1.75s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0148, 'learning_rate': 0.00013043478260869564, 'epoch': 4.21}        \r\n",
      " 87%|███████████████████████████████▎    | 100/115 [3:15:24<2:10:49, 523.30s/it]/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0086, 'learning_rate': 4.347826086956522e-05, 'epoch': 4.63}         \r\n",
      "100%|███████████████████████████████████████| 115/115 [3:37:32<00:00, 90.57s/it]\r\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001B[A\r\n",
      "  4%|█▊                                          | 2/48 [00:01<00:45,  1.02it/s]\u001B[A\r\n",
      "  6%|██▊                                         | 3/48 [00:03<01:01,  1.37s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 4/48 [00:05<01:09,  1.58s/it]\u001B[A\r\n",
      " 10%|████▌                                       | 5/48 [00:07<01:14,  1.72s/it]\u001B[A\r\n",
      " 12%|█████▌                                      | 6/48 [00:09<01:16,  1.81s/it]\u001B[A\r\n",
      " 15%|██████▍                                     | 7/48 [00:11<01:16,  1.86s/it]\u001B[A\r\n",
      " 17%|███████▎                                    | 8/48 [00:13<01:15,  1.88s/it]\u001B[A\r\n",
      " 19%|████████▎                                   | 9/48 [00:15<01:13,  1.90s/it]\u001B[A\r\n",
      " 21%|████████▉                                  | 10/48 [00:17<01:12,  1.91s/it]\u001B[A\r\n",
      " 23%|█████████▊                                 | 11/48 [00:19<01:10,  1.92s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 12/48 [00:21<01:09,  1.93s/it]\u001B[A\r\n",
      " 27%|███████████▋                               | 13/48 [00:23<01:07,  1.94s/it]\u001B[A\r\n",
      " 29%|████████████▌                              | 14/48 [00:25<01:06,  1.95s/it]\u001B[A\r\n",
      " 31%|█████████████▍                             | 15/48 [00:27<01:04,  1.95s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 16/48 [00:29<01:02,  1.96s/it]\u001B[A\r\n",
      " 35%|███████████████▏                           | 17/48 [00:31<01:01,  1.98s/it]\u001B[A\r\n",
      " 38%|████████████████▏                          | 18/48 [00:33<00:59,  1.97s/it]\u001B[A\r\n",
      " 40%|█████████████████                          | 19/48 [00:35<00:56,  1.97s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 20/48 [00:37<00:55,  1.97s/it]\u001B[A\r\n",
      " 44%|██████████████████▊                        | 21/48 [00:39<00:53,  1.99s/it]\u001B[A\r\n",
      " 46%|███████████████████▋                       | 22/48 [00:41<00:52,  2.01s/it]\u001B[A\r\n",
      " 48%|████████████████████▌                      | 23/48 [00:43<00:50,  2.01s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 24/48 [00:45<00:48,  2.01s/it]\u001B[A\r\n",
      " 52%|██████████████████████▍                    | 25/48 [00:47<00:46,  2.02s/it]\u001B[A\r\n",
      " 54%|███████████████████████▎                   | 26/48 [00:49<00:44,  2.01s/it]\u001B[A\r\n",
      " 56%|████████████████████████▏                  | 27/48 [00:51<00:42,  2.01s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 28/48 [00:53<00:40,  2.02s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▉                 | 29/48 [00:55<00:38,  2.03s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▉                | 30/48 [00:57<00:36,  2.04s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▊               | 31/48 [00:59<00:34,  2.03s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 32/48 [01:01<00:33,  2.07s/it]\u001B[A\r\n",
      " 69%|█████████████████████████████▌             | 33/48 [01:03<00:30,  2.07s/it]\u001B[A\r\n",
      " 71%|██████████████████████████████▍            | 34/48 [01:05<00:28,  2.06s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▎           | 35/48 [01:07<00:26,  2.06s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 36/48 [01:09<00:24,  2.06s/it]\u001B[A\r\n",
      " 77%|█████████████████████████████████▏         | 37/48 [01:11<00:22,  2.06s/it]\u001B[A\r\n",
      " 79%|██████████████████████████████████         | 38/48 [01:14<00:20,  2.06s/it]\u001B[A\r\n",
      " 81%|██████████████████████████████████▉        | 39/48 [01:16<00:18,  2.06s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 40/48 [01:18<00:16,  2.06s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▋      | 41/48 [01:20<00:14,  2.06s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▋     | 42/48 [01:22<00:12,  2.05s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▌    | 43/48 [01:24<00:10,  2.06s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 44/48 [01:26<00:08,  2.06s/it]\u001B[A\r\n",
      " 94%|████████████████████████████████████████▎  | 45/48 [01:28<00:06,  2.07s/it]\u001B[A\r\n",
      " 96%|█████████████████████████████████████████▏ | 46/48 [01:30<00:04,  2.07s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████ | 47/48 [01:32<00:02,  2.09s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.06791553646326065, 'eval_accuracy': 0.9879385964912281, 'eval_precision': 0.9879351874873245, 'eval_recall': 0.9879385964912281, 'eval_f1': 0.9879276447658032, 'eval_runtime': 95.7915, 'eval_samples_per_second': 31.736, 'eval_steps_per_second': 0.501, 'epoch': 4.84}\r\n",
      "100%|███████████████████████████████████████| 115/115 [3:39:08<00:00, 90.57s/it]\r\n",
      "100%|███████████████████████████████████████████| 48/48 [01:33<00:00,  1.79s/it]\u001B[A\r\n",
      "{'train_runtime': 13148.1759, 'train_samples_per_second': 4.624, 'train_steps_per_second': 0.009, 'train_loss': 0.17305654915778534, 'epoch': 4.84}\r\n",
      "100%|██████████████████████████████████████| 115/115 [3:39:08<00:00, 114.33s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../../peft_train.py \\\n",
    "--model_name ../../../pretrain_models/flan-t5-base \\\n",
    "--max_seq_len 128 \\\n",
    "--group_by_length \\\n",
    "--max_steps 200 \\\n",
    "--dataset_name ../../../text-classification/ag_news \\\n",
    "--num_labels 4 \\\n",
    "--epochs 5 \\\n",
    "--learning_rate 1e-3 \\\n",
    "--per_device_train_batch_size 64 \\\n",
    "--per_device_eval_batch_size 64 \\\n",
    "--gradient_accumulation_steps 8 \\\n",
    "--model_type SEQ_2_SEQ_LM \\\n",
    "--output_model_path ./result/flan-t5-base-ag_news-lora \\\n",
    "--need_hyperparameters_search False \\\n",
    "--enable_peft False \\\n",
    "--bnb_4bit_compute_dtype float32 \\\n",
    "--use_4b False \\\n",
    "--use_cpu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T06:14:50.546586Z",
     "start_time": "2023-12-13T02:35:35.371853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 Run code on GPU version\n",
    "Load the model together with the adapter with few lines of code! Check the snippet below to load the adapter from the Hub and run the example evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q datasets bitsandbytes einops wandb evaluate\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/llms-peft-cook-colab/experiments/flan-t5-base-full-finetune/ag_news"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\r\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\r\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\r\n",
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\r\n",
      "  warnings.warn(\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connection.py\", line 174, in _new_conn\r\n",
      "    conn = connection.create_connection(\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/util/connection.py\", line 95, in create_connection\r\n",
      "    raise err\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/util/connection.py\", line 85, in create_connection\r\n",
      "    sock.connect(sa)\r\n",
      "TimeoutError: timed out\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 715, in urlopen\r\n",
      "    httplib_response = self._make_request(\r\n",
      "                       ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 404, in _make_request\r\n",
      "    self._validate_conn(conn)\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 1058, in _validate_conn\r\n",
      "    conn.connect()\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connection.py\", line 363, in connect\r\n",
      "    self.sock = conn = self._new_conn()\r\n",
      "                       ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connection.py\", line 179, in _new_conn\r\n",
      "    raise ConnectTimeoutError(\r\n",
      "urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x2c1471750>, 'Connection to huggingface.co timed out. (connect timeout=10)')\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\r\n",
      "    resp = conn.urlopen(\r\n",
      "           ^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 799, in urlopen\r\n",
      "    retries = retries.increment(\r\n",
      "              ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/urllib3/util/retry.py\", line 592, in increment\r\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /google/flan-t5-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x2c1471750>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1247, in hf_hub_download\r\n",
      "    metadata = get_hf_file_metadata(\r\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\r\n",
      "    return fn(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1624, in get_hf_file_metadata\r\n",
      "    r = _request_wrapper(\r\n",
      "        ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 402, in _request_wrapper\r\n",
      "    response = _request_wrapper(\r\n",
      "               ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 425, in _request_wrapper\r\n",
      "    response = get_session().request(method=method, url=url, **params)\r\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\r\n",
      "    resp = self.send(prep, **send_kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\r\n",
      "    r = adapter.send(request, **kwargs)\r\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_http.py\", line 63, in send\r\n",
      "    return super().send(request, *args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/requests/adapters.py\", line 507, in send\r\n",
      "    raise ConnectTimeout(e, request=request)\r\n",
      "requests.exceptions.ConnectTimeout: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /google/flan-t5-base/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x2c1471750>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: 6c833463-b9ef-4460-b2a9-31719b50087d)')\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/utils/hub.py\", line 430, in cached_file\r\n",
      "    resolved_file = hf_hub_download(\r\n",
      "                    ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\r\n",
      "    return fn(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py\", line 1377, in hf_hub_download\r\n",
      "    raise LocalEntryNotFoundError(\r\n",
      "huggingface_hub.utils._errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/wengbenjue/sourcecode/peft/llms-peft-cook/experiments/flan-t5-base-full-finetune/ag_news/../../../peft_train.py\", line 360, in <module>\r\n",
      "    model, peft_config, tokenizer = create_and_prepare_model(script_args)\r\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/sourcecode/peft/llms-peft-cook/experiments/flan-t5-base-full-finetune/ag_news/../../../peft_train.py\", line 257, in create_and_prepare_model\r\n",
      "    model = AutoModelForSeq2SeqLM.from_pretrained(\r\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 526, in from_pretrained\r\n",
      "    config, kwargs = AutoConfig.from_pretrained(\r\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1048, in from_pretrained\r\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 622, in get_config_dict\r\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/configuration_utils.py\", line 677, in _get_config_dict\r\n",
      "    resolved_config_file = cached_file(\r\n",
      "                           ^^^^^^^^^^^^\r\n",
      "  File \"/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/transformers/utils/hub.py\", line 470, in cached_file\r\n",
      "    raise EnvironmentError(\r\n",
      "OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like google/flan-t5-base is not the path to a directory containing a file named config.json.\r\n",
      "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!python ../../../peft_train.py \\\n",
    "--model_name google/flan-t5-base \\\n",
    "--max_seq_len 2048 \\\n",
    "--group_by_length \\\n",
    "--max_steps 200 \\\n",
    "--dataset_name ../../../text-classification/ag_news \\\n",
    "--num_labels 4 \\\n",
    "--epochs 5 \\\n",
    "--learning_rate 1e-3\\\n",
    "--model_type SEQ_2_SEQ_LM \\\n",
    "--output_model_path ./result/flan-t5-base-ag_news-lora \\\n",
    "--bnb_4bit_compute_dtype float16 \\\n",
    "--need_hyperparameters_search False \\\n",
    "--enable_peft False \\\n",
    "--use_4b False\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T12:44:29.103864Z",
     "start_time": "2023-12-10T12:43:56.358711Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load your adapter from the Hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"./result/flan-t5-cup-lora\"\n",
    "base_model_name_or_path = '.../../../pretrain_models/google-flan-t5-small'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, torch_dtype=\"auto\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:37:01.962850Z",
     "start_time": "2023-12-02T16:37:01.696535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\n",
      " output prediction:  ['positive positive positive positive positive positive positive positive positive positive']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_text = \"In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "\n",
    "print(\"input sentence: \", input_text)\n",
    "print(\" output prediction: \", tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:55.202266Z",
     "start_time": "2023-12-02T16:40:55.100686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\n",
      " output prediction:  ['positive positive positive positive positive positive positive positive positive positive']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_text = \"In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "\n",
    "print(\"input sentence: \", input_text)\n",
    "print(\" output prediction: \", tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:37:04.919570Z",
     "start_time": "2023-12-02T16:37:04.379496Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Experimental Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HTMLRender:\n",
    "    def __init__(self,html_str):\n",
    "        self.html_str =html_str\n",
    "    def _repr_html_(self):\n",
    "       return self.html_str\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_accurcy_html = '''\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>eval loss</th>\n",
    "    <th>eval accuracy</th>\n",
    "    <th>eval precision</th>\n",
    "    <th>eval recall</th>\n",
    "    <th>eval f1</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color:#4C72B0;\">0.102</td>\n",
    "    <td style=\"background-color:#55A868;\">0.896</td>\n",
    "    <td style=\"background-color:#C44E52;\">0.90</td>\n",
    "     <td style=\"background-color:#8172B2;\">0.896</td>\n",
    "    <td style=\"background-color:#64B5CD;\">0.894</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "       '''\n",
    "HTMLRender(model_accurcy_html)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_html = '''\n",
    "<img src=\"./image/flan-t5-small-accuracy.png\" alt=\"flan-t5-small-accuracy\" width=\"70%\">\n",
    "'''\n",
    "HTMLRender(accuracy_html)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Load your adapter from the Hub\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
