{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Finetuning the model on financial_phrasebank dataset, that consists of pairs of text-labels to classify financial-related sentences, if they are either <span style=\"color: red;\">positive</span>, <span style=\"color: purple;\">neutral</span> or <span style=\"color: green;\">negative</span>."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.Experimental Setup1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1 Run code on CPU version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\r\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\r\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\r\n",
      "/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\r\n",
      "  warnings.warn(\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.88s/it]\r\n",
      "use AutoModelForSeq2SeqLM load  model.\r\n",
      "trainable params: 37748736 || all params: 2887505920 || trainable%: 1.3073128521932174\r\n",
      "tokenizer padding setting: </s>\r\n",
      "Sentence: seeing ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\r\n",
      "number of labels:2\r\n",
      "Running tokenizer on dataset: 100%|█| 5724/5724 [00:00<00:00, 22875.97 examples/\r\n",
      "Running tokenizer on dataset: 100%|█| 1910/1910 [00:00<00:00, 23949.82 examples/\r\n",
      "Running tokenizer on dataset: 100%|█| 19972/19972 [00:01<00:00, 19287.77 example\r\n",
      "  0%|                                                   | 0/220 [00:00<?, ?it/s]/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 8.6247, 'learning_rate': 0.0009545454545454546, 'epoch': 0.22}         \r\n",
      "{'loss': 1.2987, 'learning_rate': 0.0009090909090909091, 'epoch': 0.45}         \r\n",
      "{'loss': 0.787, 'learning_rate': 0.0008636363636363636, 'epoch': 0.67}          \r\n",
      "{'loss': 0.7179, 'learning_rate': 0.0008181818181818183, 'epoch': 0.89}         \r\n",
      " 20%|███████▍                             | 44/220 [2:27:29<9:58:26, 204.01s/it]\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001B[A\r\n",
      "  3%|█▍                                          | 2/60 [00:11<05:33,  5.75s/it]\u001B[A\r\n",
      "  5%|██▏                                         | 3/60 [00:22<07:33,  7.96s/it]\u001B[A\r\n",
      "  7%|██▉                                         | 4/60 [00:33<08:37,  9.24s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 5/60 [00:45<09:09,  9.98s/it]\u001B[A\r\n",
      " 10%|████▍                                       | 6/60 [00:56<09:16, 10.31s/it]\u001B[A\r\n",
      " 12%|█████▏                                      | 7/60 [01:07<09:29, 10.75s/it]\u001B[A\r\n",
      " 13%|█████▊                                      | 8/60 [01:19<09:24, 10.86s/it]\u001B[A\r\n",
      " 15%|██████▌                                     | 9/60 [01:30<09:25, 11.09s/it]\u001B[A\r\n",
      " 17%|███████▏                                   | 10/60 [01:42<09:21, 11.22s/it]\u001B[A\r\n",
      " 18%|███████▉                                   | 11/60 [01:53<09:04, 11.11s/it]\u001B[A\r\n",
      " 20%|████████▌                                  | 12/60 [02:04<08:58, 11.21s/it]\u001B[A\r\n",
      " 22%|█████████▎                                 | 13/60 [02:15<08:40, 11.08s/it]\u001B[A\r\n",
      " 23%|██████████                                 | 14/60 [02:26<08:36, 11.22s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 15/60 [02:37<08:22, 11.16s/it]\u001B[A\r\n",
      " 27%|███████████▍                               | 16/60 [02:49<08:11, 11.17s/it]\u001B[A\r\n",
      " 28%|████████████▏                              | 17/60 [03:00<08:03, 11.25s/it]\u001B[A\r\n",
      " 30%|████████████▉                              | 18/60 [03:11<07:46, 11.12s/it]\u001B[A\r\n",
      " 32%|█████████████▌                             | 19/60 [03:22<07:37, 11.16s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 20/60 [03:33<07:24, 11.11s/it]\u001B[A\r\n",
      " 35%|███████████████                            | 21/60 [03:44<07:14, 11.15s/it]\u001B[A\r\n",
      " 37%|███████████████▊                           | 22/60 [03:56<07:06, 11.23s/it]\u001B[A\r\n",
      " 38%|████████████████▍                          | 23/60 [04:07<06:51, 11.11s/it]\u001B[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [04:18<06:44, 11.24s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [04:29<06:28, 11.09s/it]\u001B[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [04:40<06:19, 11.16s/it]\u001B[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [04:51<06:07, 11.13s/it]\u001B[A\r\n",
      " 47%|████████████████████                       | 28/60 [05:02<05:53, 11.04s/it]\u001B[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [05:13<05:45, 11.14s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [05:24<05:30, 11.03s/it]\u001B[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [05:36<05:24, 11.18s/it]\u001B[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [05:47<05:12, 11.17s/it]\u001B[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [05:58<05:00, 11.13s/it]\u001B[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [06:09<04:50, 11.16s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [06:20<04:36, 11.05s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [06:31<04:28, 11.17s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [06:42<04:14, 11.06s/it]\u001B[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [06:53<04:03, 11.09s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [07:05<03:56, 11.24s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [07:16<03:43, 11.15s/it]\u001B[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [07:28<03:35, 11.33s/it]\u001B[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [07:39<03:22, 11.24s/it]\u001B[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [07:50<03:10, 11.19s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [08:01<02:59, 11.19s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [08:12<02:46, 11.08s/it]\u001B[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [08:23<02:36, 11.17s/it]\u001B[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [08:34<02:23, 11.03s/it]\u001B[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [08:45<02:13, 11.13s/it]\u001B[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [08:57<02:04, 11.29s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [09:09<01:55, 11.54s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [09:21<01:44, 11.57s/it]\u001B[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [09:32<01:31, 11.39s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [09:43<01:20, 11.51s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [09:55<01:09, 11.58s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [10:07<00:58, 11.68s/it]\u001B[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [10:19<00:46, 11.72s/it]\u001B[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [10:31<00:35, 11.71s/it]\u001B[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [10:42<00:23, 11.65s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [10:54<00:11, 11.73s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.6240910291671753, 'eval_accuracy': 0.6701570680628273, 'eval_precision': 0.6699366930129904, 'eval_recall': 0.6701570680628273, 'eval_f1': 0.6699873078877663, 'eval_runtime': 674.1818, 'eval_samples_per_second': 2.833, 'eval_steps_per_second': 0.089, 'epoch': 0.98}\r\n",
      " 20%|███████▍                             | 44/220 [2:41:10<9:58:26, 204.01s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [11:03<00:00, 10.88s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.6559, 'learning_rate': 0.0007727272727272727, 'epoch': 1.12}         \r\n",
      "{'loss': 0.607, 'learning_rate': 0.0007272727272727273, 'epoch': 1.34}          \r\n",
      "{'loss': 0.6009, 'learning_rate': 0.0006818181818181818, 'epoch': 1.56}         \r\n",
      "{'loss': 0.5869, 'learning_rate': 0.0006363636363636364, 'epoch': 1.79}         \r\n",
      " 40%|██████████████▉                      | 89/220 [5:06:58<7:07:17, 195.71s/it]\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001B[A\r\n",
      "  3%|█▍                                          | 2/60 [00:10<05:08,  5.32s/it]\u001B[A\r\n",
      "  5%|██▏                                         | 3/60 [00:21<07:23,  7.78s/it]\u001B[A\r\n",
      "  7%|██▉                                         | 4/60 [00:32<08:15,  8.85s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 5/60 [00:43<08:47,  9.59s/it]\u001B[A\r\n",
      " 10%|████▍                                       | 6/60 [00:54<09:03, 10.07s/it]\u001B[A\r\n",
      " 12%|█████▏                                      | 7/60 [01:05<09:03, 10.25s/it]\u001B[A\r\n",
      " 13%|█████▊                                      | 8/60 [01:16<09:08, 10.56s/it]\u001B[A\r\n",
      " 15%|██████▌                                     | 9/60 [01:27<09:00, 10.60s/it]\u001B[A\r\n",
      " 17%|███████▏                                   | 10/60 [01:37<08:54, 10.68s/it]\u001B[A\r\n",
      " 18%|███████▉                                   | 11/60 [01:48<08:46, 10.75s/it]\u001B[A\r\n",
      " 20%|████████▌                                  | 12/60 [01:59<08:31, 10.65s/it]\u001B[A\r\n",
      " 22%|█████████▎                                 | 13/60 [02:10<08:25, 10.75s/it]\u001B[A\r\n",
      " 23%|██████████                                 | 14/60 [02:20<08:11, 10.68s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 15/60 [02:31<08:05, 10.79s/it]\u001B[A\r\n",
      " 27%|███████████▍                               | 16/60 [02:42<07:55, 10.80s/it]\u001B[A\r\n",
      " 28%|████████████▏                              | 17/60 [02:53<07:42, 10.75s/it]\u001B[A\r\n",
      " 30%|████████████▉                              | 18/60 [03:04<07:34, 10.82s/it]\u001B[A\r\n",
      " 32%|█████████████▌                             | 19/60 [03:14<07:21, 10.76s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 20/60 [03:26<07:16, 10.91s/it]\u001B[A\r\n",
      " 35%|███████████████                            | 21/60 [03:36<07:04, 10.87s/it]\u001B[A\r\n",
      " 37%|███████████████▊                           | 22/60 [03:47<06:51, 10.83s/it]\u001B[A\r\n",
      " 38%|████████████████▍                          | 23/60 [03:58<06:42, 10.88s/it]\u001B[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [04:09<06:27, 10.75s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [04:20<06:19, 10.84s/it]\u001B[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [04:30<06:06, 10.79s/it]\u001B[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [04:41<05:55, 10.76s/it]\u001B[A\r\n",
      " 47%|████████████████████                       | 28/60 [04:52<05:48, 10.90s/it]\u001B[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [05:03<05:34, 10.80s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [05:14<05:27, 10.93s/it]\u001B[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [05:25<05:14, 10.86s/it]\u001B[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [05:36<05:06, 10.94s/it]\u001B[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [05:47<04:55, 10.96s/it]\u001B[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [05:58<04:42, 10.87s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [06:09<04:33, 10.95s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [06:19<04:19, 10.83s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [06:30<04:11, 10.95s/it]\u001B[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [06:41<03:59, 10.90s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [06:52<03:47, 10.86s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [07:03<03:38, 10.94s/it]\u001B[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [07:13<03:24, 10.76s/it]\u001B[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [07:25<03:15, 10.87s/it]\u001B[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [07:35<03:04, 10.83s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [07:46<02:53, 10.83s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [07:57<02:43, 10.91s/it]\u001B[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [08:08<02:31, 10.80s/it]\u001B[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [08:19<02:22, 10.94s/it]\u001B[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [08:30<02:10, 10.84s/it]\u001B[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [08:41<02:00, 10.91s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [08:52<01:49, 11.00s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [09:02<01:37, 10.85s/it]\u001B[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [09:14<01:27, 10.93s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [09:24<01:15, 10.83s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [09:35<01:05, 10.91s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [09:46<00:54, 10.96s/it]\u001B[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [09:57<00:43, 10.90s/it]\u001B[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [10:08<00:32, 10.95s/it]\u001B[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [10:19<00:21, 10.78s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [10:30<00:10, 10.98s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.6009958982467651, 'eval_accuracy': 0.6900523560209424, 'eval_precision': 0.7089124265078935, 'eval_recall': 0.6900523560209424, 'eval_f1': 0.6861765369060235, 'eval_runtime': 650.0709, 'eval_samples_per_second': 2.938, 'eval_steps_per_second': 0.092, 'epoch': 1.99}\r\n",
      " 40%|██████████████▉                      | 89/220 [5:19:21<7:07:17, 195.71s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [10:39<00:00, 10.25s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5859, 'learning_rate': 0.0005909090909090909, 'epoch': 2.01}         \r\n",
      "{'loss': 0.5855, 'learning_rate': 0.0005454545454545455, 'epoch': 2.23}         \r\n",
      " 45%|████████████████▎                   | 100/220 [5:53:47<6:42:27, 201.23s/it]/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5231, 'learning_rate': 0.0005, 'epoch': 2.46}                        \r\n",
      "{'loss': 0.5177, 'learning_rate': 0.00045454545454545455, 'epoch': 2.68}        \r\n",
      "{'loss': 0.5072, 'learning_rate': 0.00040909090909090913, 'epoch': 2.91}        \r\n",
      " 61%|█████████████████████▉              | 134/220 [7:44:41<4:40:37, 195.79s/it]\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001B[A\r\n",
      "  3%|█▍                                          | 2/60 [00:11<05:28,  5.66s/it]\u001B[A\r\n",
      "  5%|██▏                                         | 3/60 [00:22<07:30,  7.90s/it]\u001B[A\r\n",
      "  7%|██▉                                         | 4/60 [00:33<08:22,  8.98s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 5/60 [00:44<08:54,  9.71s/it]\u001B[A\r\n",
      " 10%|████▍                                       | 6/60 [00:54<09:02, 10.05s/it]\u001B[A\r\n",
      " 12%|█████▏                                      | 7/60 [01:06<09:10, 10.38s/it]\u001B[A\r\n",
      " 13%|█████▊                                      | 8/60 [01:16<09:03, 10.45s/it]\u001B[A\r\n",
      " 15%|██████▌                                     | 9/60 [01:27<09:02, 10.64s/it]\u001B[A\r\n",
      " 17%|███████▏                                   | 10/60 [01:38<08:54, 10.69s/it]\u001B[A\r\n",
      " 18%|███████▉                                   | 11/60 [01:49<08:42, 10.67s/it]\u001B[A\r\n",
      " 20%|████████▌                                  | 12/60 [02:00<08:38, 10.81s/it]\u001B[A\r\n",
      " 22%|█████████▎                                 | 13/60 [02:10<08:22, 10.69s/it]\u001B[A\r\n",
      " 23%|██████████                                 | 14/60 [02:21<08:20, 10.88s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 15/60 [02:32<08:09, 10.87s/it]\u001B[A\r\n",
      " 27%|███████████▍                               | 16/60 [02:43<07:55, 10.80s/it]\u001B[A\r\n",
      " 28%|████████████▏                              | 17/60 [02:54<07:47, 10.88s/it]\u001B[A\r\n",
      " 30%|████████████▉                              | 18/60 [03:05<07:32, 10.76s/it]\u001B[A\r\n",
      " 32%|█████████████▌                             | 19/60 [03:16<07:25, 10.88s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 20/60 [03:26<07:13, 10.83s/it]\u001B[A\r\n",
      " 35%|███████████████                            | 21/60 [03:37<07:00, 10.79s/it]\u001B[A\r\n",
      " 37%|███████████████▊                           | 22/60 [03:48<06:52, 10.85s/it]\u001B[A\r\n",
      " 38%|████████████████▍                          | 23/60 [03:59<06:37, 10.74s/it]\u001B[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [04:10<06:31, 10.89s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [04:20<06:18, 10.82s/it]\u001B[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [04:32<06:10, 10.90s/it]\u001B[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [04:42<05:59, 10.90s/it]\u001B[A\r\n",
      " 47%|████████████████████                       | 28/60 [04:53<05:47, 10.85s/it]\u001B[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [05:04<05:39, 10.94s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [05:15<05:23, 10.79s/it]\u001B[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [05:26<05:16, 10.92s/it]\u001B[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [05:37<05:05, 10.91s/it]\u001B[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [05:48<04:53, 10.85s/it]\u001B[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [05:59<04:44, 10.93s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [06:09<04:29, 10.78s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [06:20<04:22, 10.92s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [06:31<04:10, 10.91s/it]\u001B[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [06:42<03:59, 10.87s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [06:53<03:50, 10.96s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [07:04<03:36, 10.84s/it]\u001B[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [07:15<03:27, 10.94s/it]\u001B[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [07:26<03:15, 10.86s/it]\u001B[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [07:37<03:05, 10.93s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [07:48<02:54, 10.94s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [07:58<02:41, 10.79s/it]\u001B[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [08:09<02:32, 10.89s/it]\u001B[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [08:20<02:19, 10.76s/it]\u001B[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [08:31<02:11, 10.92s/it]\u001B[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [08:42<02:00, 10.91s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [08:53<01:48, 10.87s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [09:04<01:38, 10.94s/it]\u001B[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [09:14<01:26, 10.81s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [09:26<01:16, 10.94s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [09:36<01:05, 10.93s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [09:47<00:54, 10.91s/it]\u001B[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [09:58<00:43, 10.96s/it]\u001B[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [10:09<00:32, 10.87s/it]\u001B[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [10:20<00:22, 11.00s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [10:31<00:10, 10.93s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.5480843186378479, 'eval_accuracy': 0.7350785340314137, 'eval_precision': 0.7351564645813446, 'eval_recall': 0.7350785340314137, 'eval_f1': 0.7345265686785895, 'eval_runtime': 650.4343, 'eval_samples_per_second': 2.936, 'eval_steps_per_second': 0.092, 'epoch': 2.99}\r\n",
      " 61%|█████████████████████▉              | 134/220 [7:56:16<4:40:37, 195.79s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [10:39<00:00, 10.16s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.4576, 'learning_rate': 0.00036363636363636367, 'epoch': 3.13}        \r\n",
      "{'loss': 0.4943, 'learning_rate': 0.0003181818181818182, 'epoch': 3.35}         \r\n",
      "{'loss': 0.4508, 'learning_rate': 0.00027272727272727274, 'epoch': 3.58}        \r\n",
      "{'loss': 0.4443, 'learning_rate': 0.00022727272727272727, 'epoch': 3.8}         \r\n",
      " 81%|████████████████████████████▍      | 179/220 [10:54:50<5:28:58, 481.43s/it]\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001B[A\r\n",
      "  3%|█▍                                          | 2/60 [00:11<05:26,  5.62s/it]\u001B[A\r\n",
      "  5%|██▏                                         | 3/60 [00:23<07:53,  8.32s/it]\u001B[A\r\n",
      "  7%|██▉                                         | 4/60 [00:34<08:44,  9.37s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 5/60 [00:46<09:23, 10.24s/it]\u001B[A\r\n",
      " 10%|████▍                                       | 6/60 [00:57<09:33, 10.63s/it]\u001B[A\r\n",
      " 12%|█████▏                                      | 7/60 [01:09<09:35, 10.87s/it]\u001B[A\r\n",
      " 13%|█████▊                                      | 8/60 [01:20<09:38, 11.12s/it]\u001B[A\r\n",
      " 15%|██████▌                                     | 9/60 [01:31<09:23, 11.05s/it]\u001B[A\r\n",
      " 17%|███████▏                                   | 10/60 [01:43<09:19, 11.18s/it]\u001B[A\r\n",
      " 18%|███████▉                                   | 11/60 [01:54<09:03, 11.09s/it]\u001B[A\r\n",
      " 20%|████████▌                                  | 12/60 [02:05<09:03, 11.32s/it]\u001B[A\r\n",
      " 22%|█████████▎                                 | 13/60 [02:17<08:57, 11.45s/it]\u001B[A\r\n",
      " 23%|██████████                                 | 14/60 [02:29<08:45, 11.42s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 15/60 [02:40<08:40, 11.56s/it]\u001B[A\r\n",
      " 27%|███████████▍                               | 16/60 [02:52<08:24, 11.46s/it]\u001B[A\r\n",
      " 28%|████████████▏                              | 17/60 [03:04<08:20, 11.65s/it]\u001B[A\r\n",
      " 30%|████████████▉                              | 18/60 [03:15<08:10, 11.69s/it]\u001B[A\r\n",
      " 32%|█████████████▌                             | 19/60 [03:27<07:54, 11.57s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 20/60 [03:38<07:43, 11.60s/it]\u001B[A\r\n",
      " 35%|███████████████                            | 21/60 [03:49<07:25, 11.43s/it]\u001B[A\r\n",
      " 37%|███████████████▊                           | 22/60 [04:02<07:21, 11.61s/it]\u001B[A\r\n",
      " 38%|████████████████▍                          | 23/60 [04:13<07:06, 11.51s/it]\u001B[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [04:24<06:54, 11.51s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [04:36<06:43, 11.54s/it]\u001B[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [04:47<06:27, 11.40s/it]\u001B[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [04:59<06:21, 11.56s/it]\u001B[A\r\n",
      " 47%|████████████████████                       | 28/60 [05:10<06:06, 11.44s/it]\u001B[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [05:22<05:55, 11.47s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [05:33<05:45, 11.53s/it]\u001B[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [05:44<05:29, 11.36s/it]\u001B[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [05:56<05:22, 11.53s/it]\u001B[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [06:07<05:08, 11.41s/it]\u001B[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [06:19<04:59, 11.51s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [06:31<04:48, 11.56s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [06:42<04:34, 11.43s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [06:54<04:25, 11.56s/it]\u001B[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [07:05<04:10, 11.38s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [07:16<04:00, 11.48s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [07:28<03:50, 11.51s/it]\u001B[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [07:39<03:38, 11.48s/it]\u001B[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [07:51<03:27, 11.54s/it]\u001B[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [08:03<03:15, 11.53s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [08:15<03:07, 11.72s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [08:26<02:54, 11.63s/it]\u001B[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [08:38<02:43, 11.67s/it]\u001B[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [08:50<02:33, 11.79s/it]\u001B[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [09:01<02:20, 11.68s/it]\u001B[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [09:14<02:09, 11.81s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [09:25<01:57, 11.71s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [09:37<01:45, 11.77s/it]\u001B[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [09:49<01:33, 11.74s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [10:00<01:21, 11.66s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [10:12<01:11, 11.84s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [10:24<00:58, 11.67s/it]\u001B[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [10:36<00:47, 11.81s/it]\u001B[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [10:47<00:35, 11.68s/it]\u001B[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [10:59<00:23, 11.64s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [11:11<00:11, 11.75s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.5683971047401428, 'eval_accuracy': 0.7361256544502618, 'eval_precision': 0.7363912034236771, 'eval_recall': 0.7361256544502618, 'eval_f1': 0.7362067752416032, 'eval_runtime': 691.3894, 'eval_samples_per_second': 2.763, 'eval_steps_per_second': 0.087, 'epoch': 4.0}\r\n",
      " 81%|████████████████████████████▍      | 179/220 [11:06:22<5:28:58, 481.43s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [11:19<00:00, 10.73s/it]\u001B[A\r\n",
      "                                                                                \u001B[A/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.4214, 'learning_rate': 0.00018181818181818183, 'epoch': 4.02}        \r\n",
      "{'loss': 0.4141, 'learning_rate': 0.00013636363636363637, 'epoch': 4.25}        \r\n",
      "{'loss': 0.4387, 'learning_rate': 9.090909090909092e-05, 'epoch': 4.47}         \r\n",
      " 91%|███████████████████████████████▊   | 200/220 [12:21:04<1:08:31, 205.57s/it]/Users/wengbenjue/opt/anaconda3/envs/peft/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.4286, 'learning_rate': 4.545454545454546e-05, 'epoch': 4.69}         \r\n",
      "{'loss': 0.4138, 'learning_rate': 0.0, 'epoch': 4.92}                           \r\n",
      "100%|█████████████████████████████████████| 220/220 [13:27:58<00:00, 197.96s/it]\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001B[A\r\n",
      "  3%|█▍                                          | 2/60 [00:11<05:33,  5.75s/it]\u001B[A\r\n",
      "  5%|██▏                                         | 3/60 [00:22<07:31,  7.92s/it]\u001B[A\r\n",
      "  7%|██▉                                         | 4/60 [00:33<08:35,  9.20s/it]\u001B[A\r\n",
      "  8%|███▋                                        | 5/60 [00:45<09:07,  9.96s/it]\u001B[A\r\n",
      " 10%|████▍                                       | 6/60 [00:56<09:13, 10.24s/it]\u001B[A\r\n",
      " 12%|█████▏                                      | 7/60 [01:07<09:21, 10.60s/it]\u001B[A\r\n",
      " 13%|█████▊                                      | 8/60 [01:18<09:14, 10.66s/it]\u001B[A\r\n",
      " 15%|██████▌                                     | 9/60 [01:29<09:17, 10.93s/it]\u001B[A\r\n",
      " 17%|███████▏                                   | 10/60 [01:40<09:06, 10.92s/it]\u001B[A\r\n",
      " 18%|███████▉                                   | 11/60 [01:51<08:56, 10.95s/it]\u001B[A\r\n",
      " 20%|████████▌                                  | 12/60 [02:02<08:49, 11.03s/it]\u001B[A\r\n",
      " 22%|█████████▎                                 | 13/60 [02:13<08:34, 10.95s/it]\u001B[A\r\n",
      " 23%|██████████                                 | 14/60 [02:25<08:30, 11.11s/it]\u001B[A\r\n",
      " 25%|██████████▊                                | 15/60 [02:35<08:15, 11.02s/it]\u001B[A\r\n",
      " 27%|███████████▍                               | 16/60 [02:47<08:06, 11.06s/it]\u001B[A\r\n",
      " 28%|████████████▏                              | 17/60 [02:58<07:57, 11.09s/it]\u001B[A\r\n",
      " 30%|████████████▉                              | 18/60 [03:08<07:40, 10.97s/it]\u001B[A\r\n",
      " 32%|█████████████▌                             | 19/60 [03:20<07:34, 11.09s/it]\u001B[A\r\n",
      " 33%|██████████████▎                            | 20/60 [03:31<07:20, 11.00s/it]\u001B[A\r\n",
      " 35%|███████████████                            | 21/60 [03:42<07:09, 11.02s/it]\u001B[A\r\n",
      " 37%|███████████████▊                           | 22/60 [03:53<07:01, 11.10s/it]\u001B[A\r\n",
      " 38%|████████████████▍                          | 23/60 [04:04<06:45, 10.97s/it]\u001B[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [04:15<06:37, 11.04s/it]\u001B[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [04:26<06:23, 10.96s/it]\u001B[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [04:37<06:15, 11.05s/it]\u001B[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [04:48<06:07, 11.14s/it]\u001B[A\r\n",
      " 47%|████████████████████                       | 28/60 [04:59<05:52, 11.03s/it]\u001B[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [05:10<05:43, 11.09s/it]\u001B[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [05:21<05:29, 10.98s/it]\u001B[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [05:32<05:23, 11.17s/it]\u001B[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [05:44<05:12, 11.15s/it]\u001B[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [05:54<04:58, 11.05s/it]\u001B[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [06:06<04:49, 11.13s/it]\u001B[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [06:17<04:36, 11.06s/it]\u001B[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [06:29<04:31, 11.31s/it]\u001B[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [06:40<04:17, 11.21s/it]\u001B[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [06:51<04:06, 11.22s/it]\u001B[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [07:02<03:55, 11.23s/it]\u001B[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [07:13<03:40, 11.04s/it]\u001B[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [07:24<03:32, 11.17s/it]\u001B[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [07:35<03:19, 11.10s/it]\u001B[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [07:46<03:09, 11.13s/it]\u001B[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [07:58<02:59, 11.23s/it]\u001B[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [08:08<02:46, 11.09s/it]\u001B[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [08:20<02:36, 11.16s/it]\u001B[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [08:31<02:23, 11.05s/it]\u001B[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [08:42<02:14, 11.19s/it]\u001B[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [08:53<02:02, 11.18s/it]\u001B[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [09:04<01:51, 11.14s/it]\u001B[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [09:16<01:40, 11.19s/it]\u001B[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [09:26<01:28, 11.07s/it]\u001B[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [09:38<01:18, 11.19s/it]\u001B[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [09:49<01:06, 11.09s/it]\u001B[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [10:00<00:55, 11.20s/it]\u001B[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [10:11<00:44, 11.24s/it]\u001B[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [10:22<00:33, 11.08s/it]\u001B[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [10:34<00:22, 11.16s/it]\u001B[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [10:45<00:11, 11.13s/it]\u001B[A\r\n",
      "                                                                                \u001B[A\r\n",
      "\u001B[A{'eval_loss': 0.5765551328659058, 'eval_accuracy': 0.7340314136125654, 'eval_precision': 0.737865118571314, 'eval_recall': 0.7340314136125654, 'eval_f1': 0.7339293396487379, 'eval_runtime': 664.6018, 'eval_samples_per_second': 2.874, 'eval_steps_per_second': 0.09, 'epoch': 4.92}\r\n",
      "100%|█████████████████████████████████████| 220/220 [13:39:03<00:00, 197.96s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [10:53<00:00, 10.40s/it]\u001B[A\r\n",
      "{'train_runtime': 49143.2981, 'train_samples_per_second': 0.582, 'train_steps_per_second': 0.004, 'train_loss': 0.9346381057392467, 'epoch': 4.92}\r\n",
      "100%|█████████████████████████████████████| 220/220 [13:39:03<00:00, 223.38s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../../peft_train.py \\\n",
    "--model_name ../../../pretrain_models/flan-t5-xl \\\n",
    "--max_seq_len 128 \\\n",
    "--group_by_length \\\n",
    "--max_steps 200 \\\n",
    "--dataset_name ../../../text-classification/tweet_eval_irony \\\n",
    "--num_labels 2 \\\n",
    "--epochs 5 \\\n",
    "--learning_rate 1e-3 \\\n",
    "--per_device_train_batch_size 32 \\\n",
    "--per_device_eval_batch_size 32 \\\n",
    "--model_type SEQ_2_SEQ_LM \\\n",
    "--output_model_path ./result/flan-t5-xl-tweet_eval_irony-lora \\\n",
    "--bnb_4bit_compute_dtype float16 \\\n",
    "--use_4b False \\\n",
    "--use_cpu\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T04:13:32.156296Z",
     "start_time": "2023-12-11T14:34:10.068209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.2 Run code on GPU version\n",
    "Load the model together with the adapter with few lines of code! Check the snippet below to load the adapter from the Hub and run the example evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q datasets bitsandbytes einops wandb evaluate\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/llms-peft-cook-colab/experiments/flan-t5-xl-lora/tweet_eval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!python ../../../peft_train.py \\\n",
    "--model_name google/flan-t5-xl \\\n",
    "--max_seq_len 2048 \\\n",
    "--group_by_length \\\n",
    "--max_steps 200 \\\n",
    "--dataset_name ../../../text-classification/tweet_eval_irony \\\n",
    "--num_labels 2 \\\n",
    "--epochs 5 \\\n",
    "--learning_rate 1e-3 \\\n",
    "--per_device_train_batch_size 64 \\\n",
    "--per_device_eval_batch_size 64 \\\n",
    "--model_type SEQ_2_SEQ_LM \\\n",
    "--output_model_path ./result/flan-t5-xl-tweet_eval_irony-lora \\\n",
    "--bnb_4bit_compute_dtype float16 \\\n",
    "--load_in_8bit \\\n",
    "--use_4b"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load your adapter from the Hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"./result/flan-t5-cup-lora\"\n",
    "base_model_name_or_path = '.../../../pretrain_models/google-flan-t5-small'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, torch_dtype=\"auto\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:37:01.962850Z",
     "start_time": "2023-12-02T16:37:01.696535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\n",
      " output prediction:  ['positive positive positive positive positive positive positive positive positive positive']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_text = \"In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "\n",
    "print(\"input sentence: \", input_text)\n",
    "print(\" output prediction: \", tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:40:55.202266Z",
     "start_time": "2023-12-02T16:40:55.100686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sentence:  In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\n",
      " output prediction:  ['positive positive positive positive positive positive positive positive positive positive']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input_text = \"In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=10)\n",
    "\n",
    "print(\"input sentence: \", input_text)\n",
    "print(\" output prediction: \", tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:37:04.919570Z",
     "start_time": "2023-12-02T16:37:04.379496Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Experimental Result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HTMLRender:\n",
    "    def __init__(self,html_str):\n",
    "        self.html_str =html_str\n",
    "    def _repr_html_(self):\n",
    "       return self.html_str\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_accurcy_html = '''\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>eval loss</th>\n",
    "    <th>eval accuracy</th>\n",
    "    <th>eval precision</th>\n",
    "    <th>eval recall</th>\n",
    "    <th>eval f1</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"background-color:#4C72B0;\">0.102</td>\n",
    "    <td style=\"background-color:#55A868;\">0.896</td>\n",
    "    <td style=\"background-color:#C44E52;\">0.90</td>\n",
    "     <td style=\"background-color:#8172B2;\">0.896</td>\n",
    "    <td style=\"background-color:#64B5CD;\">0.894</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "       '''\n",
    "HTMLRender(model_accurcy_html)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_html = '''\n",
    "<img src=\"./image/flan-t5-small-accuracy.png\" alt=\"flan-t5-small-accuracy\" width=\"70%\">\n",
    "'''\n",
    "HTMLRender(accuracy_html)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Load your adapter from the Hub\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
